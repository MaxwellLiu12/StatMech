{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import model_with_new_lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConv(nn.Module):\n",
    "    \"\"\" Graph Convolution layer \n",
    "        \n",
    "        Args:\n",
    "        graph: tensor of shape [3, num_edges] \n",
    "               specifying (source, target, type) along each column\n",
    "        in_features: number of input features (per node)\n",
    "        out_features: number of output features (per node)\n",
    "        bias: whether to learn an edge-depenent bias\n",
    "        self_loop: whether to include self loops in message passing\n",
    "    \"\"\"\n",
    "    def __init__(self, graph, in_features: int, out_features: int,\n",
    "                 bias: bool = True, self_loop: bool = True):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        if bias:\n",
    "            self.bias = bias\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.edge_types = None\n",
    "        self.self_loop = self_loop\n",
    "        self.update_graph(graph)\n",
    "        self.forwarding_graphs_init()\n",
    "\n",
    "    def update_graph(self, graph):\n",
    "        # update the graph, adding new linear maps if needed\n",
    "        if not self.self_loop:\n",
    "            graph = graph.remove_self_loops()#removes any self_loops according to boolean\n",
    "        self.depth_assignment = graph.get_depth_assignment()\n",
    "        graph = graph.inverse_connections()#transposes the graph\n",
    "        self.graph = graph.expand_features(self.in_features, self.out_features)#expands the graph features\n",
    "        edge_types = graph.edge_types\n",
    "        if edge_types != self.edge_types:\n",
    "            self.weight = nn.Parameter(torch.Tensor(edge_types))\n",
    "            if self.bias is not None:\n",
    "                self.bias = nn.Parameter(torch.Tensor(edge_types, self.out_features))\n",
    "            #self.reset_parameters()\n",
    "        self.edge_types = edge_types\n",
    "        self.conv_size = self.graph.get_max_nodes()\n",
    "        return self\n",
    "    \n",
    "    def forwarding_graphs_init(self):\n",
    "        self.forwarding_graphs = []\n",
    "        for depth in self.depth_assignment:\n",
    "            self.forwarding_graphs.append(self.graph.select_connections(*depth))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in = self.in_features\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return 'edge_types={}, in_features={}, out_features={}, bias={}, self_loop={}'.format(\n",
    "            self.edge_types, self.in_features, self.out_features, self.bias is not None, self.self_loop)\n",
    "\n",
    "    def forward(self, input, depth = None):\n",
    "        if depth == None:\n",
    "            signal, edge_type = self.graph.sparse_graph()\n",
    "            weights = torch.gather(self.weight, 0, edge_type)\n",
    "            conv = torch.sparse_coo_tensor(signal, weights, size = self.graph.get_max_nodes())\n",
    "            output = conv.mm(input)\n",
    "        else:\n",
    "            signal, edge_type = self.forwarding_graphs[depth].sparse_graph()\n",
    "            weights = torch.gather(self.weight, 0, edge_type)\n",
    "            conv = torch.sparse_coo_tensor(signal, weights, size = self.graph.get_max_nodes())\n",
    "            output = conv.mm(input)\n",
    "        #if self.bias:\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=torch.int32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-1fbf0364c5e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_lattice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_with_new_lattice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLattice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGraphConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_lattice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-45-4cdbc2ce0a4f>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, in_features, out_features, bias, self_loop)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mself_loop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforwarding_graphs_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-4cdbc2ce0a4f>\u001b[0m in \u001b[0;36mforwarding_graphs_init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforwarding_graphs_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforwarding_graphs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepth_assignment\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforwarding_graphs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_connections\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "test_lattice = model_with_new_lattice.Lattice(4,2)\n",
    "test_layer = GraphConv(test_lattice.graph, 2, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
